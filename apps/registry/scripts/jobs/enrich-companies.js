require('dotenv').config({ path: __dirname + '/./../../.env' });
const { createClient } = require('@supabase/supabase-js');

const supabaseUrl = 'https://itxuhvvwryeuzuyihpkp.supabase.co';
const supabaseKey = process.env.SUPABASE_KEY;
const supabase = createClient(supabaseUrl, supabaseKey);

async function getCompanyInfo(companyName) {
  console.log(`ðŸ” Fetching data for company: ${companyName}`);

  const requestBody = {
    model: 'sonar-pro',
    messages: [
      {
        role: 'user',
        content: `Generate a paragraph and recent news for the company: ${companyName}. Use markdown. Only add a heading for Recent news`,
      },
    ],
    max_tokens: 2000,
    temperature: 0.9,
    top_p: 0.9,
    search_domain_filter: null,
    return_images: false,
    return_related_questions: false,
    search_recency_filter: 'year',
    top_k: 0,
    stream: false,
    presence_penalty: 0,
    frequency_penalty: 1,
    response_format: null,
  };

  const stringifiedBody = JSON.stringify(requestBody, null, 2);
  console.log('ðŸ“¨ Request body:', stringifiedBody);

  const options = {
    method: 'POST',
    headers: {
      Authorization: `Bearer ${process.env.PERPLEXITY_API_KEY}`,
      'Content-Type': 'application/json',
    },
    body: stringifiedBody,
  };

  const response = await fetch(
    'https://api.perplexity.ai/chat/completions',
    options
  );

  if (!response.ok) {
    console.error(`âŒ API Error (${response.status}):`, await response.text());
    throw new Error(`API request failed with status ${response.status}`);
  }

  const data = await response.json();
  console.log(
    `ðŸ“ Received response for ${companyName}:`,
    JSON.stringify(data, null, 2)
  );
  return data;
}

async function main() {
  console.log('ðŸš€ Starting company data collection process...');

  // Get jobs from the last 60 days
  const sixtyDaysAgo = new Date();
  sixtyDaysAgo.setDate(sixtyDaysAgo.getDate() - 60);

  console.log(`ðŸ“… Fetching jobs since: ${sixtyDaysAgo.toISOString()}`);

  const { data: jobs, error: jobsError } = await supabase
    .from('jobs')
    .select('gpt_content')
    .gte('created_at', sixtyDaysAgo.toISOString());

  if (jobsError) {
    console.error('âŒ Error fetching jobs:', jobsError);
    return;
  }

  console.log(`ðŸ“Š Found ${jobs.length} jobs to process`);

  // Extract unique companies
  const companies = new Set();
  jobs.forEach((job) => {
    try {
      const content =
        typeof job.gpt_content === 'string'
          ? JSON.parse(job.gpt_content)
          : job.gpt_content;

      if (content?.company) {
        companies.add(content.company);
      }
    } catch (e) {
      console.warn('âš ï¸ Error parsing job content:', e);
    }
  });

  console.log(`ðŸ¢ Found ${companies.size} unique companies to process`);

  // Process each company
  for (const company of companies) {
    // Check if company already exists
    const { data: existing } = await supabase
      .from('companies')
      .select('name')
      .eq('name', company)
      .single();

    if (existing) {
      console.log(`â­ï¸ Skipping ${company} - already exists in database`);
      continue;
    }

    console.log(`ðŸ”„ Processing company: ${company}`);

    try {
      const companyData = await getCompanyInfo(company);
      console.log({ companyData });
      // Save to database
      const { error: saveError } = await supabase.from('companies').insert({
        name: company,
        data: JSON.stringify(companyData),
      });

      if (saveError) {
        console.error(`âŒ Error saving ${company}:`, saveError);
      } else {
        console.log(`âœ… Successfully saved data for ${company}`);
      }
    } catch (error) {
      console.error(`âŒ Error processing ${company}:`, error);
    }
  }

  console.log('ðŸ Company data collection process completed!');
}

main().catch((error) => {
  console.error('ðŸš¨ Fatal error:', error);
  process.exit(1);
});
